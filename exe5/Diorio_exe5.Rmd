---
title: "Exercise_5_Adv_statistics"
author: "Ada D'Iorio"
output: 
html_document: 
number_sections: true 
theme: spacelab 
pdf_document:
    latex_engine: xelatex
date: "2024-05-04"
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
install.packages("coda")
library(coda)
library(scales)
```

**Exercise 1** Given the following un-normalized posterior distribution
$$ g(\theta\|x)
\propto \frac{1}{2}exp[{-\frac{(\theta+3)^2}{2}]+\frac{1}{2}exp{[-\frac{(\theta - 3)^2}{2}}}] $$

-   Draw a Markov Chain from the posterior distribution using a
    Metropolis-Hastings algorithm

Use a Norm(0, 1) as random-walk candidate density;

-   Plot the sampled distribution

```{r}


# Definizione della funzione di densità a posteriori (non normalizzata)
posterior_density <- function(theta) {
  exp(-((theta + 3)^2 / 2)) / 2 + exp(-((theta - 3)^2 / 2)) / 2
}

# Implementazione dell'algoritmo di Metropolis-Hastings
metropolis_hastings <- function(initial_theta, num_samples, proposal_sd) {
  samples <- numeric(num_samples)
  samples[1] <- initial_theta
  current_theta <- initial_theta
  
  for (i in 2:num_samples) {
    proposal_theta <- rnorm(1, mean = current_theta, sd = proposal_sd)
    acceptance_ratio <- posterior_density(proposal_theta) / posterior_density(current_theta)
    
    if (runif(1) < acceptance_ratio) {
      current_theta <- proposal_theta
    }
    
    samples[i] <- current_theta
  }
  
  return(samples)
}

# Impostazioni iniziali
initial_theta <- 0  # Theta iniziale
num_samples <- 10000  # Numero di campioni da generare
proposal_sd <- 1  # Deviazione standard della distribuzione candidata

# Generazione dei campioni
samples <- metropolis_hastings(initial_theta, num_samples, proposal_sd)

# Plot della distribuzione campionata
layout(matrix(c(1, 2), nrow = 1, ncol = 2), widths = c(2, 2))  # Impostazione per visualizzare due grafici affiancati
#par(mfrow=c(2,2), mgp=c(2,0.8,0), mar=c(3.5,3.5), oma=0.1*c(1,1))

# Istogramma della distribuzione campionata
hist(samples, breaks = 50, main = "Posterior Distribution", xlab = expression(theta), probability = TRUE)
lines(density(samples), col = "red", lwd = 2)

# Grafico di traccia
plot(samples, type = "l", main = "Trace Plot", xlab = "Iteration", ylab = expression(theta))





```

-   Analyze the chain with the \textbf{CODA} package and plot the chain
    autocorrelation;

```{r}
library(coda)

# Conversione dei campioni in un oggetto mcmc
mcmc_samples <- as.mcmc(samples)

# Analisi della catena
my_lags <- seq(0, 500, 10)
y1 <- autocorr(mcmc_samples, lags = my_lags)

# Autocorrelazione della catena
plot(my_lags, y1, ylim = c(0,1), pch = 12, col = 'navy', xlab = 'lag', ylab = 'AFC', cex = 1.3, main = 'Autocorrelation')
text(400, 0.9, paste('sigma = 1'))
text(400,0.85, sprintf("effective size: %.2f" ,effectiveSize(mcmc_samples)))
grid()


```

-   Try to use different burn-in cycles and thinning and plot the
    corresponding posterior distribution and the chain autocorrelation
    function. What are the best parameters?

```{r}
burn_in <- 1000
thinned_samples <- window(mcmc_samples, start = burn_in, thin = 10)

# Plot della distribuzione posteriore con diversi burn-in e thinning
par(mfrow = c(2, 2))

# Nessun burn-in, nessun thinning
hist(samples, breaks = 50, probability = TRUE, main = "No Burn-in, No Thinning")
curve(0.5 * dnorm(x, mean = -3, sd = 1) + 0.5 * dnorm(x, mean = 3, sd = 1), add = TRUE, col = "red", xlab = 'samples')

# Solo burn-in
samples_burnin <- samples[-(1:burn_in)]
hist(samples_burnin, breaks = 50, probability = TRUE, main = "Burn-in, No Thinning", xlab = 'samples')
curve(0.5 * dnorm(x, mean = -3, sd = 1) + 0.5 * dnorm(x, mean = 3, sd = 1), add = TRUE, col = "red")

# Solo thinning
samples_thinned <- samples[seq(1, length(samples), by = 10)]
hist(samples_thinned, breaks = 50, probability = TRUE, main = "No Burn-in, Thinning", xlab = 'samples')
curve(0.5 * dnorm(x, mean = -3, sd = 1) + 0.5 * dnorm(x, mean = 3, sd = 1), add = TRUE, col = "red")

# Burn-in e thinning
hist(as.numeric(thinned_samples), breaks = 50, probability = TRUE, main = "Burn-in e Thinning", xlab = 'samples')
curve(0.5 * dnorm(x, mean = -3, sd = 1) + 0.5 * dnorm(x, mean = 3, sd = 1), add = TRUE, col = "red")

# Plot delle autocorrelazioni
par(mfrow = c(2, 2))

#autocorr.plot(mcmc_samples, main = "No Burn-in, No Thinning")
#autocorr.plot(as.mcmc(samples_burnin), main = "Burn-in, No Thinning")
#autocorr.plot(as.mcmc(samples_thinned), main = "No Burn-in, Thinning")
#autocorr.plot(as.mcmc(thinned_samples), main = "Burn-in e Thinning")


my_lags <- seq(0, 500, 10)
y1 <- autocorr(mcmc_samples, lags = my_lags)
y2 <- autocorr(as.mcmc(samples_burnin), lags = my_lags)
y3 <- autocorr(as.mcmc(samples_thinned), lags = my_lags)
y4 <- autocorr(as.mcmc(thinned_samples), lags = my_lags)

plot(my_lags, y1, main = "No Burn-in, No Thinning", ylim = c(0,1), xlab = 'lag',
     ylab = 'ACF')
grid()
plot(my_lags, y2, main = "Burn-in, No Thinning", ylim = c(0,1), xlab = 'lag',
     ylab = 'ACF')
grid()
plot(my_lags, y3, main = "No Burn-in, Thinning", ylim = c(0,1), xlab = 'lag',
     ylab = 'ACF')
grid()
plot(my_lags, y4, main = "Burn-in e Thinning", ylim = c(0,1), xlab = 'lag',
     ylab = 'ACF')
grid()




# Which are the best parameters?
```

**Exercise 2**

A set of measured data should follow, according to the physics model
applied to them, a linear behaviour. Data are the following:

| Y   | -7.821 -1.494 -15.444 -10.807 -13.735 -14.442 -15.892 -18.326 |
|:----|:-------------------------------------------------------------:|
| X   |                      5 6 7 8 9 10 11 12                       |

Perform a simple linear regression model running a Markov Chain Monte
Carlo with JAGS, assuming that data follow the model: \$ Z[i] = a + b \p
X[i] \$ and the likelihood of the measured data follow a Gaussian
likelihood distribution: \$ Y[i] \sim dnorm(Z[i], c) \$

```{r}
library('rjags')
library('coda')


X <- c(5, 6, 7, 8, 9, 10, 11, 12)
Y <- c(-7.821, -1.494, -15.444, -10.807, -13.735, -14.442, -15.892, -18.326)

data_list <- list(X = X, Y = Y, N = length(X))
model_string <- "
model {
  for (i in 1:N) {
    Y[i] ~ dnorm(mu[i], tau)
    mu[i] <- a + b * X[i]
  }
  
  # Priors
  a ~ dnorm(0, 0.0001)
  b ~ dnorm(0, 0.0001)
  tau ~ dgamma(0.001, 0.001)
  sigma <- 1 / sqrt(tau)
}
"

writeLines(model_string, "linear_regression_model.jags") # defining the file and the model 
```

```{r}

model <- jags.model("linear_regression_model.jags", data = data_list, n.chains = 1, n.adapt = 1000)

update(model, 1000)  # Burn-in

# Campionare dalla catena di Markov
chain <- coda.samples(model, variable.names = c("a", "b", "sigma"), n.iter = 5000, thin = 10)

plot(chain, col = 'navy')

chain.df <- as.data.frame(as.mcmc(chain))

 #
 # Probability plots

 par(mfrow=c(3,2), mgp=c(2.0,0.8,0), mar=c(3.5,3.5,1,1), oma=0.1*c(1,1,1,1))
 hist(chain.df$a, main = 'Density of a', nc=100, prob=TRUE, xlab = 'Values')
 
 hist(chain.df$b, main = 'Density of b', nc = 100, prob = TRUE, xlab = 'Values')
 
 hist(chain.df$sigma, main = 'Density of sigma', nc = 100, prob = TRUE, xlab = 'Values')
 
```

Now you can constrain the parameter a, b and c to the following
intervals: \$ a \in [1,10]\$, $b \in [1,3]$ and $c \in [0.034,4]$

-   Run JAGS experimenting with the burnin and number of iterations of
    the chain.

```{r}
# First let's redefine the model 

model_string_constrained <- "
model {
  for (i in 1:N) {
    Y[i] ~ dnorm(mu[i], tau)
    mu[i] <- a + b * X[i]
  }
  
  # Priors with constraints
  a ~ dunif(1, 10)   # Uniform distribution between 1 and 10 for a
  b ~ dunif(1, 3)    # Uniform distribution between 1 and 3 for b
  tau ~ dunif(1, 5)  # Uniform distribution between 1 and 5 for tau
  sigma <- 1 / sqrt(tau)
}
"

writeLines(model_string_constrained, "linear_regression_model_constrained.jags")

model_constrained <- jags.model("linear_regression_model_constrained.jags", data = data_list, n.chains = 1, n.adapt = 1000)

# Impostare valori iniziali per a, b e c all'interno degli intervalli desiderati
init_values <- list(a = runif(1, min = 1, max = 10), b = runif(1, min = 1, max = 3), tau = runif(1, min = 0.034, max = 4))

# Eseguire l'analisi MCMC
samples_constrained1 <- coda.samples(model_constrained, variable.names = c("a", "b", "sigma"), n.iter = 5000, thin = 10, initial.values = init_values)


plot(samples_constrained1)
summary(samples_constrained1)
autocorr.plot(samples_constrained1, lag.max = 50, col = "blue", lwd = 2, lty = 'dotted')


# ------------------------- Modifica del numero di iterazioni di adattamento --------------

# n_adapt and n_iter can be used to experiment with the burn in and number of iterations

# Modifica del numero di iterazioni di adattamento
model_constrained <- jags.model("linear_regression_model_constrained.jags", data = data_list, n.chains = 1, n.adapt = 2000)

# Modifica del numero di iterazioni di campionamento
samples_constrained2 <- coda.samples(model_constrained, variable.names = c("a", "b", "sigma"), n.iter = 10000, thin = 10, initial.values = init_values)

plot(samples_constrained2)
summary(samples_constrained2)
autocorr.plot(samples_constrained2, lag.max = 50, col = "blue", lwd = 2, lty = 'dotted')

#plot(my_lags, y1, main = "No Burn-in, No Thinning", ylim = c(0,1), xlab = 'lag',     ylab = 'ACF')



```

-   Plot the evolution of the chains and the posterior distributions of
    a and b.

```{r}
# Non so se è quello che ho già fatto nel punto di sopra
# Traccia l'evoluzione delle catene
plot(samples_constrained1[, c("a", "b")])

# Traccia le distribuzioni posteriori di a e b
densplot(samples_constrained1[, c("a", "b")], main = "Posterior Distributions of a and b", 
         xlab = "Parameter Value", ylab = "Density", col = c("blue", "red"), lwd = 2, lty = "solid", grid = TRUE)


# -----------------------------------------

plot(samples_constrained2[, c("a", "b")])

# Traccia le distribuzioni posteriori di a e b
densplot(samples_constrained2[, c("a", "b")], main = "Posterior Distributions of a and b", 
         xlab = "Parameter Value", ylab = "Density", col = c("blue", "red"), lwd = 2, lty = "solid", grid = TRUE)

```

-   Compute the 95% credibility interval for the parameters.

```{r}

# Calcola l'intervallo di credibilità al 95% per a e b
cred_interval_a <- HPDinterval(samples_constrained[, "a"], prob = 0.95)
cred_interval_b <- HPDinterval(samples_constrained[, "b"], prob = 0.95)

# Stampa solo i valori degli intervalli di credibilità
print(paste("Credibility Interval for a:", cred_interval_a))
print(paste("Credibility Interval for b:", cred_interval_b))

```

-   Using the obtained posterior distributions, compute the posterior
    distribution of \$ \sigma = \frac{1}{\sqrt(c)}\$

```{r}
# Ottieni le distribuzioni posteriori di c
# Ottieni le distribuzioni posteriori di c
posterior_c <- samples_constrained[, "sigma"]

# Calcola la distribuzione posteriore di sigma
posterior_sigma <- 1 / sqrt(posterior_c)

# Traccia la distribuzione posteriore di sigma
densplot(posterior_sigma, main = "Posterior Distribution of Sigma", xlab = "Sigma Value", ylab = "Density", col = "blue")


## RIVEDERE 
  
```

**Exercise 3** Suppose we observe the following values:

\$ x = 2.06, 5.56, 7.93, 6.56, 205 \$

and we assume that the data come from a gaussian distribution with
unknown mean $m$ and variance $s^2$: - Build a simple JAGS model and run
a Markov Chain Monte Carlo to obtain the posterior distribution of the
mean and variance.

```{r}
library('rjags')
library('coda')

# Dati osservati
x <- c(2.06, 5.56, 7.93, 6.56, 205)

# Lunghezza dei dati
N <- length(x)

# Creazione del file di testo per il modello JAGS
model_string <- "
model {
  # Prior per la media
  mu ~ dnorm(0, 1.0E-6)
  
  # Prior per la deviazione standard (considerando una deviazione standard uniforme)
  sigma ~ dunif(0, 100)
  
  # Likelihood
  for (i in 1:N) {
    x[i] ~ dnorm(mu, 1/(sigma^2))
  }
}
"

writeLines(model_string, "gaussian_model.jags")

# Generazione di dati fittizi
data_list <- list(x = x, N = N)

# Creazione del modello JAGS
model <- jags.model(textConnection(model_string), data = data_list, n.chains = 3)

# Esecuzione della catena di Markov Monte Carlo
mcmc_samples <- coda.samples(model, variable.names = c('mu', 'sigma'), n.iter = 5000)

# Riepilogo dei risultati
summary(mcmc_samples)




```

Assume uniform prior distributions for the parameters,
$m \sim dunif(-10, 10)$ and $s \sim dunif(0,50)$. - Compute also the
posterior distribution for $m/s$.

```{r}

# Estraiamo campioni per m e s dalla catena MCMC
mcmc_samples <- as.matrix(mcmc_samples)

# Estraiamo i campioni per m e s
m <- mcmc_samples[, "mu"]
s <- mcmc_samples[, "sigma"]

# Calcoliamo la distribuzione posteriore di m/s utilizzando i campioni estratti
m_divided_by_s <- m / s

hist(m_divided_by_s, main = 'Posterior distribution of m/s', xlab = 'Values', ylab = 'Frequency', col = 'red')

# Tracciamo la distribuzione posteriore di m/s
#densplot(m_divided_by_s, main = "Posterior Distribution of m/s", xlab = "m/s", ylab = "Density", col = "blue")



## RIVEDERE 

```

**Exercise 4**

The dataset that Edwin Hubble used to show that galaxies are moving
either away or towards us are given in the following table:

| D| 0.0032 0.0034 0.214 0.263 0.275|
| V| 170 290 -130 -70 -185|
|:------|:---------------------------------------------------------------:|
| D | 0.275 0.45 0.5 0.5 0.63 | 
| V | -220 200 290 270 200 |
|:------|:---------------------------------------------------------------:|
| D \| 0.8 0.9 0.9 0.9 0.9 \| 
| V \| 920 450 500 500 500 |
|:------\|:---------------------------------------------------------------:|
| D \| 2 2 2 2 \| 
| V \| 500 850 800 1090 \|

-   Using this dataset define a JAGS model to fit data with the
    following: \$ V[i] \sim dnorb(b  \cdot  D[i],  c) \$

where $V$ represent the velocity in units $km/s$, $D$ is the observed
distance (in units of parsec), and $b$ and $c$ are two parameters of the
model.

```{r}
library(rjags)
library(coda)

# Dati osservati
D <- c(0.0032, 0.0034, 0.214, 0.263, 0.275,
       0.275, 0.45, 0.5, 0.5, 0.63,
       0.8, 0.9, 0.9, 0.9, 0.9,
       2, 2, 2, 2)
V <- c(170, 290, -130, -70, -185,
       -220, 200, 290, 270, 200,
       920, 450, 500, 500, 500,
       500, 850, 800, 1090)

# Numero di dati
N <- length(D)

# Creazione del file di testo per il modello JAGS
model_string <- "
model {
  # Prior per b e c
  b ~ dunif(-1000, 1000)
  c ~ dunif(0, 1000)
  
  # Likelihood
  for (i in 1:N) {
    V[i] ~ dnorm(b * D[i], 1 / (c^2))
  }
}"

# Generazione di dati fittizi
data_list <- list(D = D, V = V, N = N)

# Creazione del modello JAGS
model <- jags.model(textConnection(model_string), data = data_list, n.chains = 1)

```
Assume facoltative prior distribution: 
- Plot the evolution of the chains, the posterior distribution of the parameters and the $95%$
credibility interval.

```{r}

# Esecuzione della catena di Markov Monte Carlo
mcmc_samples <- coda.samples(model, variable.names = c("b", "c"), n.iter = 5000)

# Riepilogo dei risultati
summary(mcmc_samples)

# Traccia l'evoluzione delle catene
plot(mcmc_samples)

# Traccia le distribuzioni posteriori di b e c
densplot(mcmc_samples[, c("b", "c")], main = 'Posterior Distributions of b and c',
         xlab = 'Parameter Value', ylab = 'Density', col = c('blue', 'red'), lwd = 2, lty = 'solid', grid = TRUE)

# Calcola e traccia gli intervalli di credibilità al 95%
cred_interval_b <- HPDinterval(mcmc_samples[, "b"], prob = 0.95)
cred_interval_c <- HPDinterval(mcmc_samples[, "c"], prob = 0.95)
print(paste("Credibility Interval for b:", cred_interval_b))
print(paste("Credibility Interval for c:", cred_interval_c))





```
